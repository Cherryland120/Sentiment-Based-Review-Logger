{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b5f49c-b017-4fcf-81ec-153957b080b7",
   "metadata": {},
   "source": [
    "# Sentiment-Based Review Logger\n",
    "\n",
    "This project is an AI-powered sentiment analysis system designed to classify user-submitted reviews and log negative feedback for further analysis. Built using **PyTorch**, **TorchText**, and **NLP techniques**, the system prompts users for their name and product review, then processes the input using a **pre-trained sentiment classification model**.\n",
    "\n",
    "## Key Features:\n",
    "- Interactive User Input – Prompts users for their name and review in a Jupyter Notebook environment.\n",
    "- Sentiment Classification – Utilizes a trained deep learning model to categorize reviews as Negative, Positive, or Neutral.\n",
    "- Automated Review Logging – If a review is classified as negative, it is automatically saved in a structured CSV file (negative_reviews.csv).\n",
    "- Scalable Data Handling – Uses pandas for efficient data storage, allowing easy analysis of recurring negative feedback trends.\n",
    "- Customizable File Path – The CSV file can be saved in any specified directory for centralized logging.\n",
    "\n",
    "## Use Cases:\n",
    "- Businesses can track **customer dissatisfaction** trends to improve their products.\n",
    "- AI researchers can **fine-tune NLP models** using real-world feedback.\n",
    "- Developers can **extend the project** to include real-time review monitoring in web applications.\n",
    "\n",
    "## Dependencies\n",
    "- torch\n",
    "- torchtext\n",
    "- spacy ('en_core_web_sm' language model)\n",
    "- pandas\n",
    "\n",
    "Author: Tamunowunari-Tasker Anointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bdeb817-5570-48cd-b4c3-1d4553f9842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries from PyTorch and TorchText\n",
    "import torchtext.data.utils as tdu  # For tokenization utilities\n",
    "import torchtext.vocab as tv        # For vocabulary building\n",
    "import torch.nn as nn               # For neural network components like Embedding\n",
    "import torch                        # For tensor operations\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd92f85-8242-4c80-b625-f9caecfc7899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset of simple sentences\n",
    "dataset = [\n",
    "    (\"I like cats\", 1), # Positive\n",
    "    (\"I hate dogs\", 0), # Negative\n",
    "    (\"I'm impartial to hippos\", 2)] # Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52c6943-4444-4fa4-9d49-ddce6effaa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer using SpaCy's small English model\n",
    "tokenizer = tdu.get_tokenizer('spacy', language = 'en_core_web_sm') # get_tokenizer() is unique to torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "799feb94-cab3-4a55-8b99-c6a8fcf9d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to yield tokens from each sentence in the dataset\n",
    "def yield_tokens(data_iter):\n",
    "    \"\"\"\n",
    "    Tokenizes each sentence in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_iter (iter): An iterator over the dataset.\n",
    "        \n",
    "    Yields:\n",
    "        list: A list of tokens for each sentence.\n",
    "    \"\"\"\n",
    "    for sentence, _  in data_iter:\n",
    "        yield tokenizer(sentence) # gives you one value at a time but remembers where it left off, ready to continue when called again.\n",
    "\n",
    "# Create an iterator over the dataset\n",
    "data_iter = iter(dataset) # iter is an inbuilt function in Python that returns an iterator from a list, tuple or a custom dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a7ce61-c232-4595-a92f-0667a21eeb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from the tokenized dataset\n",
    "vocab = tv.build_vocab_from_iterator(yield_tokens(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37a7a600-2b9a-432f-9dca-b64cb9fe29bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'m\", 'cats', 'dogs', 'hate', 'hippos', 'impartial', 'like', 'to']\n"
     ]
    }
   ],
   "source": [
    "# Display the vocabulary as a list of words (index-to-string mapping)\n",
    "print(vocab.get_itos()) # get_itos() returns the list/bag of words. This results in a bag of 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "893442fd-228a-4e79-a227-f167395d308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentences to token indices\n",
    "input_indexes = lambda data: [torch.tensor(vocab(tokenizer(sentence))) for sentence, _ in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d68b787a-0ba8-4d06-b0de-f3fed703ecd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token indices: [tensor([0, 7, 2]), tensor([0, 4, 3]), tensor([0, 1, 6, 8, 5])]\n"
     ]
    }
   ],
   "source": [
    "# Convert dataset sentences to token indices\n",
    "index = input_indexes(dataset) # index has three tensors\n",
    "print(\"Token indices:\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "435fc9fc-5f76-42f4-aa2d-dc93465dce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentiment labels\n",
    "labels = torch.tensor([label for _, label in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b51cb7d-e31b-406e-b04c-6888e2a37176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set embedding dimensions (number of features each word vector will have)\n",
    "embedding_dim = 3 # Each word will be represented in a 3D vector space\n",
    "\n",
    "# Number of unique words in the vocabulary\n",
    "n_embedding = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d46cecac-9279-44d0-be88-c47f7a5b01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EmbeddingBag layer to get sentence-level embeddings\n",
    "embedding_bag = nn.EmbeddingBag(num_embeddings=n_embedding, embedding_dim=embedding_dim, mode='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85d2358f-6c19-4146-88e1-695cb6c4f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare flattened token indices and offsets for EmbeddingBag\n",
    "index_flat = torch.cat(index)\n",
    "offsets = torch.tensor([0] + [len(sample) for sample in index[:-1]]).cumsum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33e2da2a-efa7-44c5-bffb-08d89af09b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple sentiment classifier model\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, embedding_bag, embedding_dim, num_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.embedding_bag = embedding_bag\n",
    "        self.fc = nn.Linear(embedding_dim, num_classes)  # Linear layer for classification\n",
    "        \n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding_bag(text, offsets)  # Get sentence embeddings\n",
    "        return self.fc(embedded)  # Pass through linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "804dcd73-77b1-4048-9451-7beba3668c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "num_classes = 3  # Positive, Negative, Neutral\n",
    "model = SentimentClassifier(embedding_bag, embedding_dim, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28f25b8a-6b75-4891-b05e-0b49c848cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb05dc5d-27dc-4339-9155-f5d9abc9eba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.0028\n",
      "Epoch [20/100], Loss: 0.8270\n",
      "Epoch [30/100], Loss: 0.6588\n",
      "Epoch [40/100], Loss: 0.5029\n",
      "Epoch [50/100], Loss: 0.3663\n",
      "Epoch [60/100], Loss: 0.2570\n",
      "Epoch [70/100], Loss: 0.1776\n",
      "Epoch [80/100], Loss: 0.1240\n",
      "Epoch [90/100], Loss: 0.0890\n",
      "Epoch [100/100], Loss: 0.0663\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(index_flat, offsets)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f443ddcf-3146-4f30-9c7c-068f2826051c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'I hate cats hippos dogs' -> Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# Testing the classifier\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_sentence = \"I hate cats hippos dogs\"\n",
    "    test_tokens = torch.tensor(vocab(tokenizer(test_sentence)))\n",
    "    test_offset = torch.tensor([0])\n",
    "    \n",
    "    output = model(test_tokens, test_offset)\n",
    "    predicted_label = torch.argmax(output).item()\n",
    "    \n",
    "    sentiment_map = {0: \"Negative\", 1: \"Positive\", 2: \"Neutral\"}\n",
    "    print(f\"Sentence: '{test_sentence}' -> Sentiment: {sentiment_map[predicted_label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4971068-35b8-4bfc-87e6-89fef2a02232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def classify_review(review):\n",
    "    \"\"\"Classify sentiment of a review using the trained model.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_tokens = torch.tensor(vocab(tokenizer(review)))\n",
    "        test_offset = torch.tensor([0])\n",
    "        output = model(test_tokens, test_offset)\n",
    "        predicted_label = torch.argmax(output).item()\n",
    "    return predicted_label  # Returns 0 (Negative), 1 (Positive), or 2 (Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30250f00-dfa8-4289-a2dd-bb46df46cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_negative_review(name, review, filename=\"negative_reviews.csv\"):\n",
    "    \"\"\"Save negative reviews to a CSV file.\"\"\"\n",
    "    file_exists = os.path.exists(filename)\n",
    "\n",
    "    # Create DataFrame from new entry\n",
    "    new_entry = pd.DataFrame([[name, review]], columns=[\"Name\", \"Review\"])\n",
    "\n",
    "    # Append to CSV, creating it if necessary\n",
    "    if file_exists:\n",
    "        new_entry.to_csv(filename, mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        new_entry.to_csv(filename, mode=\"w\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "675ff34f-a479-4da9-88c0-16fb28ae71db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your name:  Anointina\n",
      "Share your review of the product:  I hate dogs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your review was classified as: Negative\n",
      "Your negative review has been recorded.\n"
     ]
    }
   ],
   "source": [
    "# --- User Interaction ---\n",
    "name = input(\"Enter your name: \")\n",
    "review = input(\"Share your review of the product: \")\n",
    "\n",
    "sentiment_label = classify_review(review)\n",
    "sentiment_map = {0: \"Negative\", 1: \"Positive\", 2: \"Neutral\"}\n",
    "print(f\"\\nYour review was classified as: {sentiment_map[sentiment_label]}\")\n",
    "\n",
    "# Save negative reviews\n",
    "if sentiment_label == 0:\n",
    "    save_negative_review(name, review)\n",
    "    print(\"Your negative review has been recorded.\")\n",
    "else:\n",
    "    print(\"Thank you for your feedback!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
